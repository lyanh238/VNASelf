{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\agents\\assistant\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_12416\\1475732251.py:41: DeprecationWarning: Using DoclingParseV4DocumentBackend for InputFormat.IMAGE is deprecated. Images should use ImageDocumentBackend via ImageFormatOption. Automatically correcting the backend, please update your code to avoid this warning.\n",
      "  converter = DocumentConverter(\n",
      "2025-11-26 15:08:04,874 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-26 15:08:05,007 - INFO - Going to convert document batch...\n",
      "2025-11-26 15:08:05,010 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 44ae89a68fc272bc7889292e9b5a1bad\n",
      "2025-11-26 15:08:05,037 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-26 15:08:05,042 - INFO - Registered picture descriptions: ['vlm', 'api']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document: D:\\agents\\assistant\\uploads\\20251126_134514_17249f00.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 15:08:05,068 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-26 15:08:05,086 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-11-26 15:08:05,819 - INFO - Accelerator device: 'cpu'\n",
      "\u001b[32m[INFO] 2025-11-26 15:08:05,849 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-26 15:08:05,875 [RapidOCR] download_file.py:60: File exists and is valid: D:\\agents\\assistant\\env\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-26 15:08:05,877 [RapidOCR] main.py:53: Using D:\\agents\\assistant\\env\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-26 15:08:06,067 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-26 15:08:06,071 [RapidOCR] download_file.py:60: File exists and is valid: D:\\agents\\assistant\\env\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-26 15:08:06,072 [RapidOCR] main.py:53: Using D:\\agents\\assistant\\env\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-26 15:08:06,146 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-26 15:08:06,176 [RapidOCR] download_file.py:60: File exists and is valid: D:\\agents\\assistant\\env\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-11-26 15:08:06,177 [RapidOCR] main.py:53: Using D:\\agents\\assistant\\env\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-11-26 15:08:06,372 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-11-26 15:08:06,386 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-26 15:08:08,674 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-26 15:08:10,051 - INFO - Processing document 20251126_134514_17249f00.pdf\n",
      "2025-11-26 15:08:25,348 - INFO - Finished converting document 20251126_134514_17249f00.pdf in 20.48 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Le Nguyen Quoc Anh\n",
      "\n",
      "Undergraduate, FPT University, Ho Chi Minh, Vietnam lenguyenquocanh2005@gmail.com - 0909427722 - www.linkedin.com/in/quocanh - Github: lyanh238\n",
      "\n",
      "## CAREER OBJECTIVE\n",
      "\n",
      "An AI major student passionate about Machine Learning and Data Science, aiming to explore how machines learn from language and data to create intelligent and insightful systems.\n",
      "\n",
      "## EDUCATION\n",
      "\n",
      "FPT University , Ho Chi Minh City, Vietnam\n",
      "\n",
      "GPA:\n",
      "\n",
      "8.1/10\n",
      "\n",
      "The Degree of Bachelor in Artificial Intelligence\n",
      "\n",
      "## TECHNICAL SKILLS\n",
      "\n",
      "- Cloud Platforms: Microsoft Azure, Supabase, NeonDB\n",
      "- Frameworks: Scikit-learn, Tensorflow, Pytorch, Flask, FastAPI\n",
      "- Languages: Python, R, JavaScript\n",
      "- Libraries: Numpy, Pandas, Scipy, OpenCV, Matplotlib, Librosa, Seaborn, Statsmodels, Beautiful Soup, Selenium\n",
      "- IDE: VS code, Pycharm, Jupyter notebook\n",
      "- Environments: Anaconda, Docker\n",
      "- OS:\n",
      "\n",
      "Window\n",
      "\n",
      "- Database: MySQL, PostgreSQL\n",
      "\n",
      "- Version Control:\n",
      "\n",
      "GIT\n",
      "\n",
      "- Tools: Dataiku, Exel, Power BI, n8n\n",
      "\n",
      "## WORKING EXPERIENCE\n",
      "\n",
      "## FPT Software\n",
      "\n",
      "## Project: QAI HONDA OCD\n",
      "\n",
      "Role: Data Analyst Intern\n",
      "\n",
      "## Description:\n",
      "\n",
      "Worked on data processing, statistical analysis, and data visualization tasks to extract insights from customer datasets. Combined Machine Learning (ML) and Deep Learning (DL) algorithms to identify quality patterns and performance trends within automotive manufacturing data. Supported the AI research team in developing analytical solutions to improve operational decision-making.\n",
      "\n",
      "## Key Responsibilities:\n",
      "\n",
      "- Processed and cleaned large-scale customer datasets for analysis and modeling\n",
      "- Applied statistical methods and ML/DL models to detect patterns and predict outcomes\n",
      "- Created dashboards and visual reports to communicate insights effectively\n",
      "- Assisted in troubleshooting data and model-related issues\n",
      "- Contributed to research and implementation of AI-driven analytical pipelines\n",
      "\n",
      "## Technologies:\n",
      "\n",
      "- AI Algorithms: Machine Learning, Deep Learning\n",
      "\n",
      "- Languages: Python, R\n",
      "\n",
      "- Tools:\n",
      "\n",
      "Dataiku, Jupyter Notebook, Microsoft Excel\n",
      "\n",
      "Sep, 2023 Current\n",
      "\n",
      "Quy Nhon, Vietnam\n",
      "\n",
      "September 2025 - Present\n",
      "\n",
      "## Project: Battery Quality\n",
      "\n",
      "Role: AI Engineer\n",
      "\n",
      "## Description:\n",
      "\n",
      "Supported the battery team in developing an LLM-based chatbot using the Retrieval-Augmented Generation (RAG) framework. The system allows users to input battery conditions and receive AI-generated insights and suggestions for quality improvement. Implemented a semantic search pipeline leveraging Azure OpenAI Service and Azure Cognitive Search for vector-based document retrieval, ensuring accurate and contextually relevant responses.\n",
      "\n",
      "## Key Responsibilities:\n",
      "\n",
      "- Processed and transformed tabular and text data for RAG pipeline integration\n",
      "- Designed and implemented RAG workflow with vector search integration\n",
      "- Managed and preprocessed domain-specific battery data for embedding and indexing\n",
      "- Troubleshot API connections, embedding pipelines, and query performance issues\n",
      "\n",
      "## Technologies:\n",
      "\n",
      "- Language: Python\n",
      "- Frameworks &amp; Libraries: OpenAI SDK, Azure SDK, LangChain, azure-search-documents\n",
      "- Database &amp; Storage: Azure Cognitive Search, Azure Blob Storage\n",
      "- Cloud Platform: Microsoft Azure (Azure OpenAI Service)\n",
      "- Tools: Visual Studio Code, Azure Portal\n",
      "\n",
      "## PROJECTS\n",
      "\n",
      "## Enhanced Classroom Attendance System using SCRFD &amp; ArcFace for Facial Recognition\n",
      "\n",
      "Team Leader -github.com/lyanh238/facerecognition\n",
      "\n",
      "Dec 2024 - Jan 2025\n",
      "\n",
      "- Engineered a face recognition model using SCRFD for face detection and ArcFace (ResNet-50) with Additive Angular Margin Loss, achieving high-precision identification.\n",
      "- Optimized the pipeline for CPU performance by separating detection and recognition, reducing computation and memory load per face crop.\n",
      "- Technologies: Python, PyTorch, ONNX, OpenCV, FastAPI.\n",
      "\n",
      "## Vietnamese Named Entity Recognition\n",
      "\n",
      "Architecture &amp; Evaluation Support -github.com/duclld1709/NER\n",
      "\n",
      "Dec 2024 - Jan 2025\n",
      "\n",
      "- Assisted in developing and evaluating CRF-based NER models using PhoBERT embeddings to improve recognition accuracy on the VLSP2016 dataset.\n",
      "- Compared CRF and Softmax architectures to analyze performance trade-offs in entity extraction tasks.\n",
      "- Technologies: PyTorch, HuggingFace Transformers, sklearn.\n",
      "\n",
      "## VNASelf - Intelligent Assistant Powered by Multi-Agent Architecture\n",
      "\n",
      "AI &amp; Full-Stack Engineer - github.com/lyanh238/VNASelf\n",
      "\n",
      "Oct 2025 - Nov 2025\n",
      "\n",
      "- Developed an AI-powered assistant with a multi-agent architecture for intelligent Google Calendar automation, OCR and daily task.\n",
      "- Designed a supervisor-agent framework using LangGraph and LangChain for intelligent task routing and natural language operations.\n",
      "- Integrated OpenAI GPT models with custom tool-binding and asynchronous execution for contextual understanding.\n",
      "- Integrate cloud data storage on NeonDB or Supabase to support embeddings for RAG and COR tasks using PaddleOCR and VietOCR\n",
      "- Built stateful multi-turn dialogue handling using LangGraph MemorySaver.\n",
      "- Developed a React + Vite frontend with real-time chat interface and Context API-based authentication.\n",
      "- Implemented secure authentication, encryption utilities, and token-based API communication.\n",
      "- Created a Python async backend with RESTful APIs and a modular microservice structure.\n",
      "- Designed for scalability and containerization with Docker.\n",
      "- Technologies: React, Vite, Context API, JavaScript, Python, LangGraph, LangChain, OpenAI API, asyncio, Google Cloud, Docker, NeonDB, Supabase.\n",
      "\n",
      "## CERTIFICATIONS\n",
      "\n",
      "## Dataiku\n",
      "\n",
      "- Core Designer Certificate\n",
      "- ML Practitioner Certificate\n",
      "- Advanced Designer Certificate\n",
      "- Generative AI Practitioner Certificate\n",
      "- MLOps Practitioner Certificate\n",
      "- Developer Certificate\n",
      "\n",
      "## IELTS\n",
      "\n",
      "IELTS (Academic): 6.0 (overall score)\n",
      "\n",
      "Listening: 6.0 - Reading: 6.0\n",
      "\n",
      "Speaking: 5.5 - Writing: 6.0\n",
      "\n",
      "## Additional Courses\n",
      "\n",
      "- Databases and SQL for Data Science with Python\n",
      "- Machine Learning with Python\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.models.utils.generation_utils import (\n",
    "    DocTagsRepetitionStopper,\n",
    ")\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s:%(name)s:%(message)s\")\n",
    "\n",
    "\n",
    "# Set up logging to see when repetition stopping is triggered\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Replace with a local path if preferred.\n",
    "# source = \"https://ibm.biz/docling-page-with-table\" # Example that shows no repetitions.\n",
    "source = r\"D:\\agents\\assistant\\uploads\\20251126_134514_17249f00.pdf\"  # Example that creates repetitions.\n",
    "print(f\"Processing document: {source}\")\n",
    "\n",
    "###### USING GRANITEDOCLING WITH CUSTOM REPETITION STOPPING\n",
    "\n",
    "## Using standard Huggingface Transformers (most portable, slowest)\n",
    "custom_vlm_options = vlm_model_specs.GRANITEDOCLING_TRANSFORMERS.model_copy()\n",
    "\n",
    "# Uncomment this to use MLX-accelerated version on Apple Silicon\n",
    "# custom_vlm_options = vlm_model_specs.GRANITEDOCLING_MLX.model_copy() # use this for Apple Silicon\n",
    "\n",
    "\n",
    "# Create custom VLM options with repetition stopping criteria\n",
    "custom_vlm_options.custom_stopping_criteria = [\n",
    "    DocTagsRepetitionStopper(N=32)\n",
    "]  # check for repetitions for every 32 new tokens decoded.\n",
    "\n",
    "pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=custom_vlm_options,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.IMAGE: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "doc = converter.convert(source=source).document\n",
    "\n",
    "print(doc.export_to_markdown())\n",
    "\n",
    "## Using a remote VLM inference service (for example VLLM) - uncomment to use\n",
    "\n",
    "# custom_vlm_options = ApiVlmOptions(\n",
    "#     url=\"http://localhost:8000/v1/chat/completions\",  # LM studio defaults to port 1234, VLLM to 8000\n",
    "#     params=dict(\n",
    "#         model=vlm_model_specs.GRANITEDOCLING_TRANSFORMERS.repo_id,\n",
    "#         max_tokens=8192,\n",
    "#         skip_special_tokens=True,  # needed for VLLM\n",
    "#     ),\n",
    "#     headers={\n",
    "#         \"Authorization\": \"Bearer YOUR_API_KEY\",\n",
    "#     },\n",
    "#     prompt=vlm_model_specs.GRANITEDOCLING_TRANSFORMERS.prompt,\n",
    "#     timeout=90,\n",
    "#     scale=2.0,\n",
    "#     temperature=0.0,\n",
    "#     response_format=ResponseFormat.DOCTAGS,\n",
    "#     custom_stopping_criteria=[\n",
    "#         DocTagsRepetitionStopper(N=1)\n",
    "#     ],  # check for repetitions for every new chunk of the response stream\n",
    "# )\n",
    "\n",
    "\n",
    "# pipeline_options = VlmPipelineOptions(\n",
    "#     vlm_options=custom_vlm_options,\n",
    "#     enable_remote_services=True, # required when using a remote inference service.\n",
    "# )\n",
    "\n",
    "# converter = DocumentConverter(\n",
    "#     format_options={\n",
    "#         InputFormat.IMAGE: PdfFormatOption(\n",
    "#             pipeline_cls=VlmPipeline,\n",
    "#             pipeline_options=pipeline_options,\n",
    "#         ),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# doc = converter.convert(source=source).document\n",
    "\n",
    "# print(doc.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421eb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_1976\\866389351.py:4: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import Column, Integer, String\n",
    "from sqlalchemy.orm import declarative_base\n",
    "# Create a base class\n",
    "Base = declarative_base()\n",
    "# Define a model class\n",
    "class User(Base):\n",
    "   __tablename__ = 'users'\n",
    "   id = Column(Integer, primary_key=True)\n",
    "   username = Column(String(50))\n",
    "   email = Column(String(100))\n",
    "   def __repr__(self):\n",
    "       return f\"<User(username='{self.username}', email='{self.email}')>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d7924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
